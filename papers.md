## Repository of papers: 

- ~**[Evaluating Verifiability in Generative Search Engines](https://arxiv.org/abs/2304.09848)** by Nelson F. Liu, Tianyi Zhang, Percy Liang~
- ~**[On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research](https://arxiv.org/abs/2304.12397)** by Luiza Pozzobon, Beyza Ermis, Patrick Lewis, Sara Hooker~
- ~**[Dissecting Recall of Factual Associations in Auto-Regressive Language Models](https://arxiv.org/abs/2304.14767)** by Mor Geva, Jasmijn Bastings, Katja Filippova, Amir Globerson~
- ~**[Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks](https://arxiv.org/abs/2305.10160)** by Alon Jacovi, Avi Caciularu, Omer Goldman, Yoav Goldberg~
- ~**[Evaluating the Factual Consistency of Large Language Models Through Summarization](https://arxiv.org/abs/2211.08412)** by Derek Tam, Anisha Mascarenhas, Shiyue Zhang, Sarah Kwan, Mohit Bansal, Colin Raffel~
- ~**[Moving beyond “algorithmic bias is a data problem”](https://www.sciencedirect.com/science/article/pii/S2666389921000611)** by Sara Hooker~
- ~**[DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature](https://arxiv.org/abs/2301.11305)** by Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D. Manning, Chelsea Finn~
- ~**[Poisoning Language Models During Instruction Tuning](https://arxiv.org/abs/2305.00944)** by Alexander Wan, Eric Wallace, Sheng Shen, Dan Klein~
- ~**[Auditing large language models: a three-layered approach](https://arxiv.org/abs/2302.08500)** by Jakob Mökander, Jonas Schuett, Hannah Rose Kirk, Luciano Floridi~
- ~**[Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy](https://arxiv.org/abs/2210.17546)** by Daphne Ippolito, Florian Tramèr, Milad Nasr, Chiyuan Zhang, Matthew Jagielski, Katherine Lee, Christopher A. Choquette-Choo, Nicholas Carlini~
- ~**[Quantifying Memorization Across Neural Language Models](https://arxiv.org/abs/2202.07646)** by Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, Chiyuan Zhang~
- ~**[Stronger Together: on the Articulation of Ethical Charters, Legal Tools, and Technical Documentation in ML](https://arxiv.org/abs/2305.18615)** by Giada Pistilli, Carlos Munoz Ferrandis, Yacine Jernite, Margaret Mitchell~
- ~**[On the Reliability of Watermarks for Large Language Models](https://arxiv.org/abs/2306.04634)** by John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, Tom Goldstein~
- ~**[Debiased Fine-Tuning for Vision-language Models by Prompt Regularization](https://arxiv.org/abs/2301.12429)** by Beier Zhu, Yulei Niu, Saeil Lee, Minhoe Hur, Hanwang Zhang~
- ~**[Grokking of Hierarchical Structure in Vanilla Transformers](https://arxiv.org/abs/2305.18741)** by Shikhar Murty, Pratyusha Sharma, Jacob Andreas, Christopher Manning~
- ~**[RWKV: Reinventing RNNs for the Transformer Era](https://arxiv.org/abs/2305.13048)** by Bo Peng et al.~
- ~**[Retentive Network: A Successor to Transformer for Large Language Models](https://arxiv.org/abs/2307.08621)** Yutao Sun, Li Dong, Shaohan Huang, Shuming Ma, Yuqing Xia, Jilong Xue, Jianyong Wang, Furu Wei~
- ~**[Backpack Language Models](https://arxiv.org/abs/2305.16765)** by John Hewitt, John Thickstun, Christopher Manning, Percy Liang~
- ~**[Organizational Governance of Emerging Technologies: AI Adoption in Healthcare](https://arxiv.org/abs/2304.13081)** by Jee Young Kim et al.~
- ~**[The Gradient of Generative AI Release: Methods and Considerations](https://arxiv.org/abs/2302.04844)** by Irene Solaiman~
- ~**[Predictability and Surprise in Large Generative Models](https://dl.acm.org/doi/abs/10.1145/3531146.3533229)** by Deep Ganguli et al.~
- ~**[Towards Climate Awareness in NLP Research](https://aclanthology.org/2022.emnlp-main.159/)** by Daniel Hershcovich, Nicolas Webersinke, Mathias Kraus, Julia Bingler, Markus Leippold~
<!--Extending Context Length-->  
- ~**[LongNet: Scaling Transformers to 1,000,000,000 Tokens](https://arxiv.org/abs/2307.02486)** by Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, Wenhui Wang, Nanning Zheng, Furu Wei~
- ~**[Extending Context Window of Large Language Models via Positional Interpolation](https://arxiv.org/abs//2306.15595)** by Shouyuan Chen, Sherman Wong, Liangjian Chen, Yuandong Tian~
- ~**[Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172)** by Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang~
<!--Scaling-->
- ~**[No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models](https://arxiv.org/pdf/2307.06440.pdf)** by Jean Kaddour, Oscar Key, Piotr Nawrot, Pasquale Minervini, Matt J. Kusner1~
<!--Decoding Innovations-->  
- ~**[Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)** by Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan~
- ~**[Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding](https://arxiv.org/abs/2307.15337)** Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, Yu Wang~
<!--Crowdsurcing Annotations-->  
- ~**[Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks](https://arxiv.org/abs/2306.07899)** by Veniamin Veselovsky, Manoel Horta Ribeiro, Robert West~
- ~**[LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs](https://arxiv.org/pdf/2307.10168.pdf)** by Tongshuang Wu et al.~
- ~**[Design Choices for Crowdsourcing Implicit Discourse Relations: Revealing the Biases Introduced by Task Design](https://arxiv.org/abs/2304.00815)** by Valentina Pyatkin, Frances Yung, Merel C.J. Scholman, Reut Tsarfaty, Ido Dagan, Vera Demberg~
- ~**[Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies](https://openreview.net/forum?id=eYlLlvzngu)** by Gati Aher, Rosa I. Arriaga, Adam Tauman Kalai~
<!--Privacy and Security in LLMs-->  
- ~**[What Does it Mean for a Language Model to Preserve Privacy?](https://dl.acm.org/doi/pdf/10.1145/3531146.3534642)** by Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, Florian Tramèr~
- ~**[Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/abs/2307.15043)** by Andy Zou, Zifan Wang, J. Zico Kolter, Matt Fredrikson~
<!--Transformer ML-->  
- ~**[A Study on Transformer Configuration and Training Objective](https://arxiv.org/abs/2205.10505)** by Fuzhao Xue et al.~
- ~**[Auto-Regressive Next-Token Predictors are Universal Learners](https://arxiv.org/abs/2309.06979)** by Eran Malach~
- ~**[Transformers as Support Vector Machines](https://arxiv.org/abs/2308.16898)** by Davoud Ataee Tarzanagh, Yingcong Li, Christos Thrampoulidis, Samet Oymak~
- ~**[Stabilizing Transformer Training by Preventing Attention Entropy Collapse](https://arxiv.org/abs/2303.06296)** by Shuangfei Zhai et al.~
- <!--Insruction Tuning and Aligning with Humans Preferences -->
- **[Are Emergent Abilities in Large Language Models just In-Context Learning?](https://arxiv.org/abs/2309.01809)** by Sheng Lu, Irina Bigoulaeva, Rachneet Sachdeva, Harish Tayyar Madabushi, Iryna Gurevych
- **[How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources](https://arxiv.org/abs/2306.04751)** by Yizhong Wang et al.
- **[Exploring the Benefits of Training Expert Language Models over Instruction Tuning](https://openreview.net/forum?id=VAA1itvsNQ)** by Joel Jang et al.
- **[On the Exploitability of Instruction Tuning](https://arxiv.org/abs/2306.17194)** by Manli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping, Chaowei Xiao, Tom Goldstein
- **[Pretraining Language Models with Human Preferences](https://openreview.net/forum?id=AT8Iw8KOeC)** by Tomasz Korbak et al.
<!--Auditing-->  
- **[Automatically Auditing Large Language Models via Discrete Optimization](https://openreview.net/forum?id=YaXiH2B0Sb)** by Erik Jones, Anca Dragan, Aditi Raghunathan, Jacob Steinhardt
- **[Bring Your Own Data! Self-Supervised Evaluation for Large Language Models](https://arxiv.org/abs/2306.13651v1)** by Neel Jain et el.
- **[Causality-aware Concept Extraction based on Knowledge-guided Prompting](https://arxiv.org/abs/2305.01876)** by Siyu Yuan, Deqing Yang, Jinxi Liu, Shuyu Tian, Jiaqing Liang, Yanghua Xiao, Rui Xie
- **[Compositional Generalization without Trees using Multiset Tagging and Latent Permutations](https://arxiv.org/abs/2305.16954)** by Matthias Lindemann, Alexander Koller, Ivan Titov
- **[A New Direction in Stance Detection: Target-Stance Extraction in the Wild](https://aclanthology.org/2023.acl-long.560/)** by Yingjie Li, Krishna Garg, Cornelia Caragea
- **[Topic-Guided Sampling For Data-Efficient Multi-Domain Stance Detection](https://arxiv.org/abs/2306.00765)** by Erik Arakelyan, Arnav Arora, Isabelle Augenstein
<!--Reproducility/ Consistency/ Fairness in Evaluations-->
- **[REFORMS: Reporting Standards for Machine Learning Based Science](https://arxiv.org/abs/2308.07832)** by Sayash Kapoor et al.
- **[Predictive Multiplicity in Probabilistic Classification](https://arxiv.org/abs/2206.01131)** by Jamelle Watson-Daniels, David C. Parkes, Berk Ustun
- **[Is My Prediction Arbitrary? The Confounding Effects of Variance in Fair Classification Benchmarks](https://arxiv.org/abs/2301.11562)** by A. Feder Cooper et al.
- **[Troubling Trends in Machine Learning Scholarship](https://arxiv.org/abs/1807.03341)** by Zachary C. Lipton, Jacob Steinhardt
<!--Data Attribution and Model Editing-->  
- **[TRAK: Attributing Model Behavior at Scale](https://openreview.net/forum?id=PBRArApxMh)** by Sung Min Park, Kristian Georgiev, Andrew Ilyas, Guillaume Leclerc, Aleksander Madry
- **[Evaluating the Ripple Effects of Knowledge Editing in Language Models](https://arxiv.org/abs/2307.12976)** by Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, Mor Geva
- **[On Provable Copyright Protection for Generative Models](https://openreview.net/forum?id=qRAHZVnQNY)** by Nikhil Vyas, Sham M. Kakade, Boaz Barak
- **[Tools for Verifying Neural Models' Training Data](https://arxiv.org/abs/2307.00682)** by Dami Choi, Yonadav Shavit, David Duvenaud
<!--Memorisation and Generalisation-->  
- **[Explaining grokking through circuit efficiency](https://arxiv.org/abs/2309.02390)** by Vikrant Varma, Rohin Shah, Zachary Kenton, János Kramár, Ramana Kumar
<!--Multi-linguality-->  
- **[Multilingual Event Extraction from Historical Newspaper Adverts](https://arxiv.org/abs/2305.10928)** by Nadav Borenstein, Natália da Silva Perez, Isabelle Augenstein
- **[When Does Translation Require Context? A Data-driven, Multilingual Exploration](https://aclanthology.org/2023.acl-long.36/)** by Patrick Fernandes, Kayo Yin, Emmy Liu, André Martins, Graham Neubig
- **[Differential Privacy, Linguistic Fairness, and Training Data Influence: Impossibility and Possibility Theorems for Multilingual Language Models](https://openreview.net/forum?id=SP6w4sVCyp)** by Phillip Rust, Anders Søgaard
<!--Efficient Training, Fine-tuning, Inference-->  
- **[Large Language Models Can Be Easily Distracted by Irrelevant Context](https://openreview.net/forum?id=JSZmoN03Op)** by Freda Shi et al.
- **[Cold-Start Data Selection for Better Few-shot Language Model Fine-tuning: A Prompt-based Uncertainty Propagation Approach](https://arxiv.org/abs/2209.06995)** by Yue Yu, Rongzhi Zhang, Ran Xu, Jieyu Zhang, Jiaming Shen, Chao Zhang
- **[Full Parameter Fine-tuning for Large Language Models with Limited Resources](https://arxiv.org/abs//2306.09782)** by Kai Lv, Yuqing Yang, Tengxiao Liu, Qinghui Gao, Qipeng Guo, Xipeng Qiu
- **[Stack More Layers Differently: High-Rank Training Through Low-Rank Updates](https://arxiv.org/abs/2307.05695)** Vladislav Lialin, Namrata Shivagunde, Sherin Muckatira, Anna Rumshisky
- **[Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer](https://arxiv.org/abs/2203.03466)** by Greg Yang et al.
- **[The case for 4-bit precision: k-bit Inference Scaling Laws](https://openreview.net/forum?id=i8tGb1ab1j)** by Tim Dettmers, Luke Zettlemoyer
<!--Explanation and Rationalization-->  
- **[Faithfulness Tests for Natural Language Explanations](https://arxiv.org/abs/2305.18029)** by Pepa Atanasovaet el.
- **[Towards Trustworthy Explanation: On Causal Rationalization](https://openreview.net/forum?id=fvTgh4MNUV)** by Wenbo Zhang, TONG WU, Yunlong Wang, Yong Cai, Hengrui Cai
- **[Rule By Example: Harnessing Logical Rules for Explainable Hate Speech Detection](https://aclanthology.org/2023.acl-long.22/)** by Christopher Clarke, Matthew Hall, Gaurav Mittal, Ye Yu, Sandra Sajeev, Jason Mars, Mei Chen
<!--Bias and Fairness-->  
- **[A Comparative Study on the Impact of Model Compression Techniques on Fairness in Language Models](https://aclanthology.org/2023.acl-long.878/)** by Krithika Ramesh, Arnav Chavan, Shrey Pandit, Sunayana Sitaram
- **[Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting](https://arxiv.org/abs/2110.05367)** by Zahra Fatemi, Chen Xing, Wenhao Liu, Caimming Xiong, Zahra Fatemi
- **[Data Feedback Loops: Model-driven Amplification of Dataset Biases](https://openreview.net/forum?id=8JXMDw2xGa)** by Rohan Taori, Tatsunori Hashimoto
- **[The Bias Amplification Paradox in Text-to-Image Generation](https://yanaiela.github.io/papers/bias-amplification-paradox.pdf)** by Preethi Seshadri, Sameer Singh, Yanai Elazar
- **[FairPrism: Evaluating Fairness-Related Harms in Text Generation](http://users.umiacs.umd.edu/~hal/docs/daume23fairprism.pdf)** by Eve Fleisig et el.
- **["I wouldn’t say offensive but...": Disability-Centered Perspectives on Large Language Models](https://research.google/pubs/pub52358/)** by Vinitha Gadiraju, Shaun Kane, Sunipa Dev, Alex Taylor, Ding Wang, Emily Denton, Robin Brewer
- **[Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models](https://aclanthology.org/2023.acl-long.84.pdf)** by Myra Cheng, Esin Durmus, Dan Jurafsky
- **[Whose Opinions Do Language Models Reflect?](https://openreview.net/forum?id=7IRybndMLU)** by Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, Tatsunori Hashimoto
